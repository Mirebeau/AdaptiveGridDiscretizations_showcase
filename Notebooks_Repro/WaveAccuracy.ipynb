{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2610af50-4de9-4681-bee5-472490a0d362",
   "metadata": {},
   "source": [
    "# Adaptive PDE discretizations on Cartesian grids\n",
    "## Volume : Reproducible research\n",
    "## Part : Comparison of acoustic and elastic schemes\n",
    "## Chapter : Comparing dispersions, and error w.r.t exact solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861e618-875e-405a-8e04-d4e2fead02cb",
   "metadata": {},
   "source": [
    "In this notebook, we compare a several discretization schemes for the acoustic and elastic wave equations. The criteria are : \n",
    "- the faithfullness of the numerical dispersion relation, which is compared with the exact dispersion relation.\n",
    "- the numerical error in synthetic test cases, obtained by diffeomorphic deformation of homogeneous media, and where an exact solution is known.\n",
    "\n",
    "We compare a number of discretization schemes based on the Selling decomposition, with the baseline provided by the centered and crisscross schemes (Acoustic), and the Lebedev scheme for the elastic wave equation. These scheme implementations can be found in the notebooks on [comparisons of schemes for wave equations](ElasticComparisons.ipynb) and [high order methods for wave equations](HighOrderWaves.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf541d-9029-4905-a47e-0be483ff9655",
   "metadata": {},
   "source": [
    "[**Summary**](Summary.ipynb) of volume Reproducible research, this series of notebooks.\n",
    "\n",
    "[**Main summary**](../Summary.ipynb) of the Adaptive Grid Discretizations \n",
    "\tbook of notebooks, including the other volumes.\n",
    "\n",
    "# Table of contents\n",
    "  * [1. Acoustic dispersion](#1.-Acoustic-dispersion)\n",
    "    * [1.1 Two dimensions](#1.1-Two-dimensions)\n",
    "    * [1.2 Three dimensions, needle-like anisotropy](#1.2-Three-dimensions,-needle-like-anisotropy)\n",
    "    * [1.3 Three dimensions, plate-like anisotropy](#1.3-Three-dimensions,-plate-like-anisotropy)\n",
    "  * [2. Elastic dispersion](#2.-Elastic-dispersion)\n",
    "    * [2.1 Two dimensions](#2.1-Two-dimensions)\n",
    "    * [2.2 Two dimensions, deformed materials](#2.2-Two-dimensions,-deformed-materials)\n",
    "    * [2.3 Three dimensions](#2.3-Three-dimensions)\n",
    "    * [2.4 Three dimensions, deformed materials](#2.4-Three-dimensions,-deformed-materials)\n",
    "  * [3. Exact solutions in inhomogeneous domains](#3.-Exact-solutions-in-inhomogeneous-domains)\n",
    "    * [3.1 Domain deformation](#3.1-Domain-deformation)\n",
    "    * [3.2 Planewaves in the homogeneous domain](#3.2-Planewaves-in-the-homogeneous-domain)\n",
    "    * [3.3 Inhomogeneous parameters and exact solution](#3.3-Inhomogeneous-parameters-and-exact-solution)\n",
    "    * [3.4 Acoustic accuracy comparison](#3.4-Acoustic-accuracy-comparison)\n",
    "    * [3.5 Elastic accuracy comparison](#3.5-Elastic-accuracy-comparison)\n",
    "\n",
    "\n",
    "\n",
    "**Acknowledgement.** Some of the experiments presented in these notebooks are part of \n",
    "ongoing research with Ludovic Métivier and Da Chen.\n",
    "\n",
    "Copyright Jean-Marie Mirebeau, Centre Borelli, ENS Paris-Saclay, CNRS, University Paris-Saclay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7705cc73-fb57-4d0c-b661-e0fcabb54420",
   "metadata": {},
   "source": [
    "## 0. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2de391-cba6-45ef-8670-cb9af1bfd929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T08:46:12.318498Z",
     "iopub.status.busy": "2024-04-30T08:46:12.318228Z",
     "iopub.status.idle": "2024-04-30T08:46:12.327115Z",
     "shell.execute_reply": "2024-04-30T08:46:12.326656Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,\"..\")\n",
    "#from Miscellaneous import TocTools; print(TocTools.displayTOC('WaveAccuracy','Repro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c519c0b-d3a2-4d90-bf33-983da17bf396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T08:46:12.329699Z",
     "iopub.status.busy": "2024-04-30T08:46:12.329495Z",
     "iopub.status.idle": "2024-04-30T08:46:12.338540Z",
     "shell.execute_reply": "2024-04-30T08:46:12.337884Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ElasticComparisons.py, line 46)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/opt/miniconda3/envs/agd-hfm_dev_310/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3433\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\n\u001b[0;31m    from agd.ExportedCode.Notebooks_Div import ElasticComparisons as ec\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Dropbox/Programmes/GithubM1/AdaptiveGridDiscretizations/agd/ExportedCode/Notebooks_Div/ElasticComparisons.py:46\u001b[0;36m\u001b[0m\n\u001b[0;31m    pad = q[*(slice(None),)*axis,shift,None] if bc=='Constant' else 0.\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from agd.ExportedCode.Notebooks_Div import ElasticComparisons as ec\n",
    "from agd.ExportedCode.Notebooks_Div import HighOrderWaves as how\n",
    "from agd.ExportedCode.Notebooks_Algo import TensorSelling as ts\n",
    "from agd.Eikonal.HFM_CUDA import AnisotropicWave as aw\n",
    "from agd import Metrics\n",
    "from agd.Metrics import Riemann\n",
    "from agd.Metrics.Seismic import Thomsen,Hooke\n",
    "from agd import LinearParallel as lp\n",
    "from agd import AutomaticDifferentiation as ad\n",
    "from agd import FiniteDifferences as fd\n",
    "from agd import Eikonal\n",
    "from agd.Plotting import savefig; savefig.dirName = 'Images/WaveAccuracy/'\n",
    "norm = ad.Optimization.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5feb374-e446-49ef-849a-d84a57e0af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from types import SimpleNamespace\n",
    "π = np.pi\n",
    "np.set_printoptions(linewidth=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c68241-7919-4144-921c-e906fbf93fd0",
   "metadata": {},
   "source": [
    "### 0.1 Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39e0d74-fabb-4de9-80e3-b9b37fde4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_avg(arr,ord=2,axis=None,weights=1):\n",
    "    \"\"\"Averaged norm of an array, along the specified axes, with the specified weights\"\"\"\n",
    "    # Normalize axis, if needed\n",
    "    if axis is None: axis = tuple(range(arr.ndim))\n",
    "    if np.ndim(axis)==0 and axis!=-1: axis=(axis,)\n",
    "    if isinstance(axis,tuple):\n",
    "        ndim = len(axis)\n",
    "        arr = np.moveaxis(arr,axis,tuple(range(ndim)))\n",
    "        weights = np.broadcast_to(weights,arr.shape[:ndim])\n",
    "        weights = weights / np.sum(weights)\n",
    "        arr = np.moveaxis(arr.reshape((-1,*arr.shape[ndim:])),0,-1)\n",
    "        weights = weights.reshape(-1)\n",
    "        axis=-1\n",
    "    assert axis==-1\n",
    "    if ord==np.inf: return np.max(arr,axis=-1)\n",
    "    return np.sum(arr**ord * weights,axis=-1)**(1/ord)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52768a89-a6f6-4c3d-b222-aec2b7cb3885",
   "metadata": {},
   "source": [
    "Compute a rotation which maps the vertical axis a given unit vector to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315bd33d-72aa-48ba-876c-c69f90d7fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_params(u):\n",
    "    \"\"\"Compute the rotation mapping (0,1) onto u, assumed to be unit.\"\"\"\n",
    "    if len(u)==2: return np.arctan2(-u[0],u[1]) \n",
    "    ax = np.array((-u[1],u[0],np.zeros_like(u[0])))\n",
    "    θ = np.arccos(u[2]/np.linalg.norm(u))\n",
    "    return θ,ax/np.linalg.norm(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b3b206-75a2-4e1a-85bb-0f52868f7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([-1.,2])\n",
    "θ = rotation_params(u)\n",
    "assert np.allclose(lp.rotation(θ) @ np.array([0,1.]), u/np.linalg.norm(u))\n",
    "u = np.array([1.,2,-3])\n",
    "θ,ax = rotation_params(u)\n",
    "assert np.allclose(lp.rotation(θ,ax) @ np.array([0,0,1.]),u/np.linalg.norm(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a07747-6c90-4e0c-9836-035bca358a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vti_orientations(nθ,vdim,prune=False):\n",
    "    \"\"\"A collection of orientations, and unit wavenumbers, with the given sampling density\"\"\"\n",
    "    # Construction of orientations. We need to : \n",
    "    # - cover the projective space with the wavenumbers\n",
    "    # - regarding anisotropy, and given the scheme invariances, it is sufficient to cover x>=y>=z>=0\n",
    "    if vdim==2: \n",
    "        θ = np.linspace(0,π,nθ,endpoint=False)\n",
    "        k = np.array((np.cos(θ),np.sin(θ))) # Cover y>=0 (projective space)\n",
    "        θ = np.linspace(0,π/4,nθ//4) \n",
    "        uθ = np.array((np.cos(θ),np.sin(θ))) # Cover x>=y>=0 (part of first quadrant)\n",
    "        weights=1\n",
    "    elif vdim==3: # Three dimensional case\n",
    "        θ = np.linspace(0,2*π,nθ*2, endpoint=False)[:,None]\n",
    "        ϕ = np.linspace(0,π/2,nθ//2,endpoint=False)[None,:]\n",
    "        k = np.array( (np.cos(θ)*np.cos(ϕ),np.sin(θ)*np.cos(ϕ),np.ones_like(θ)*np.sin(ϕ)) ) # Cover z>=0 (projective space)\n",
    "        weights_k = np.cos(ϕ)+0.*θ\n",
    "        k = k.reshape((3,-1)) \n",
    "        weights_k = weights_k.reshape(-1)\n",
    "        select = np.logical_and(k[0]>=k[1],k[1]>=k[2])\n",
    "        uθ = k[:,select] # Cover x>=y>=z>=0\n",
    "        weights_θ = weights_k[select]\n",
    "        # TODO : remove this. Not used anymore. 6D Voronoi decomposition, has been fixed\n",
    "        if prune: uθ+=1e-3; uθ/=np.linalg.norm(uθ,axis=0); uθ=uθ[:,:44]; weights_θ=weights_θ[:44] \n",
    "        weights = weights_θ[:,None]*weights_k[None,:]\n",
    "    return uθ,k,weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1aeda0-2f4c-43ec-bc73-190be2908cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_filename(str): \n",
    "    for key,val in (', ','-'),(' ','-'),('κ','kappa'): str = str.replace(key,val)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a104c-e2a3-451f-98f7-f532adb9e3ea",
   "metadata": {},
   "source": [
    "## 1. Acoustic dispersion\n",
    "\n",
    "We compare the accuracy of the different discretizations, at a given number of points per wavelength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e85b06-b030-43fb-a5d4-dfec1f29b3a2",
   "metadata": {},
   "source": [
    "### 1.1 Two dimensions \n",
    "\n",
    "Let us choose the parameters that we'll compare the schemes on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361671a1-b73f-4dbf-8378-00d891844af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion_exactAcoustic(k,ρ,D): return np.sqrt(lp.dot_VAV(k,D/ρ,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d62967-526c-4018-9412-ac524f4220a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_Acoustic2D = {\n",
    "    'aniso':np.array([1,1.2,1.5,2,2.5,3,4,5,6,8,10,13]), # Anisotropy ratios\n",
    "    'ppw':[3,4,5,6,8,10,12,15], # Points per wavelength\n",
    "\n",
    "    'scheme':['centered2','centered4','centered6','crisscross2','crisscross4','Selling2','Selling4','Selling6'],\n",
    "    'style':[':',':',':','--','--','-','-','-'], # Plot style, and color below\n",
    "    'color':['blue','purple','cyan','green','olive','red','orange','brown'],\n",
    "    'dispersion':[*(ec.dispersion_AcousticCentered,)*3,*(ec.dispersion_AcousticCrissCross,)*2,*(how.dispersion_a,)*3],\n",
    "    'dispersion_exact':dispersion_exactAcoustic,\n",
    "    'decomp':(lambda D:Eikonal.VoronoiDecomposition(D)), 'use_decomp':(False,)*5+(True,)*3, # Precompute Selling decomposition\n",
    "    \n",
    "    'ord':(1,2,np.inf), # norm order for the relative error \n",
    "    'ω_ref':'geom', # Alternatively : 'max', 'min', None\n",
    "    'dt':1e-4, # Vanishingly small : only interested in spatial dispersion here\n",
    "\n",
    "    'nθ':60, 'prune':False, # Angular discretization \n",
    "    'vdim':2,\n",
    "    'mk_aniso':None, 'name':None, # To fill\n",
    "    'mode':None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95847f93-50ad-460a-9e5e-03ce6e8019c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersions(default=params_Acoustic2D,**kwargs):\n",
    "    \"\"\"\n",
    "    Compare the numerical dispersions of various schemes.\n",
    "    Output: \n",
    "        - result : array with shape (ppw, scheme, error order, anisotropy type or parameter)\n",
    "        - params : updated parameters\n",
    "    \"\"\"\n",
    "    p = SimpleNamespace(**default) # parameters\n",
    "    for key,val in kwargs.items(): assert key in dir(p); p.__setattr__(key,val)\n",
    "    p.order_x = [int(scheme[-1]) for scheme in p.scheme]\n",
    "    indices = [default['scheme'].index(scheme) for scheme in p.scheme]\n",
    "    p.style = [p.style[i] for i in indices]\n",
    "    p.color = [p.color[i] for i in indices]\n",
    "    p.dispersion = [p.dispersion[i] for i in indices]\n",
    "\n",
    "    uθ,k,weights = vti_orientations(p.nθ,p.vdim,p.prune)\n",
    "    \n",
    "    D_ = np.moveaxis(np.array([p.mk_aniso(uθ[...,None],aniso) for aniso in p.aniso]),0,2) # Last axis is for wavenumber k\n",
    "    dt = p.dt # Fixed time step, often very small\n",
    "    ρ = 1. # Fixed unit density\n",
    "    shape = len(p.aniso),uθ.shape[1],k.shape[1]\n",
    "    D_ = fd.as_field(D_,shape,singleton_in=True,singleton_out=True)\n",
    "\n",
    "    # Choose a reference frequency, for which wavenumbers have norm approx 1\n",
    "    def get_mode(x): return x if p.mode is None else x[p.mode]\n",
    "    k_ = k[:,None,None,:]\n",
    "\n",
    "    ω_exact = get_mode(p.dispersion_exact(k_,ρ,D_))\n",
    "    ω_min,ω_max = np.min(ω_exact,axis=(1,2)),np.max(ω_exact,axis=(1,2))\n",
    "    if p.ω_ref is not None:  # Normalize wavenumbers for the reference frequency\n",
    "        ω_ref = {'min':ω_min,'max':ω_max,'geom':np.sqrt(ω_min*ω_max)}[p.ω_ref]\n",
    "        k_ = k_* ω_ref[:,None,None]/ω_exact\n",
    "        ω_exact = get_mode(p.dispersion_exact(k_,ρ,D_))\n",
    "\n",
    "    result_ppw = []\n",
    "    D_decomp = p.decomp(D_) # Precompute Voronoi's decomposition (actually useless, even in dim 6)\n",
    "    for ppw in p.ppw:\n",
    "        dx = 2*π/ppw # Points per wavelength\n",
    "        result_scheme = []\n",
    "        for dispersion,order_x,use_decomp in zip(p.dispersion,p.order_x,p.use_decomp):\n",
    "            ω_scheme = get_mode(dispersion(k_,ρ,(D_decomp if use_decomp else D_),dx,dt,order_x)[0])\n",
    "            rel_err = np.abs(1-ω_scheme/ω_exact)\n",
    "            result_scheme.append([norm_avg(rel_err,ord,axis=(1,2),weights=weights) for ord in p.ord])\n",
    "        result_ppw.append(result_scheme)\n",
    "\n",
    "    return np.array(result_ppw),p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8dab2d-f39f-4426-9459-578f5f1fb26d",
   "metadata": {},
   "source": [
    "The following cell can take a little time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f71944d-5ed0-4ab9-ad08-9a69d701880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 ms, sys: 5.29 ms, total: 21.5 ms\n",
      "Wall time: 26.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def mk_needle(uθ,κ): return Riemann.needle(uθ,1,κ).m\n",
    "result_2d = dispersions(ppw=[4,6,10],mk_aniso=mk_needle,name='Two dimensional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2b80b1-c267-4d75-b2f7-ca6e826e3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_Acoustic(result,params,ppw=6,ord=2,anisos=None,schemes=None,styles=None):\n",
    "    ippw = list(params.ppw).index(ppw)\n",
    "    iord = list(params.ord).index(ord)\n",
    "    ianiso = [list(params.aniso).index(aniso) for aniso in anisos] if anisos else np.arange(len(params.aniso))\n",
    "    ischeme = [list(params.scheme).index(scheme) for scheme in schemes] if schemes else np.arange(len(params.scheme))\n",
    "    if styles is None: styles = [params.style[i] for i in ischeme]\n",
    "    \n",
    "    plt.title(f\"{params.name} dispersions, {ppw=}, {ord=}\")\n",
    "    plt.ylabel(\"Dispersion error\")\n",
    "    plt.xlabel(\"Anisotropy\")\n",
    "    for i,style in zip(ischeme,styles):\n",
    "        plt.semilogy(params.aniso[ianiso],result[ippw,i,iord,ianiso],style,color=params.color[i],label=params.scheme[i])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6140cc5b-d991-4480-855f-ae2a8af6c2b8",
   "metadata": {},
   "source": [
    "We have the following observations:\n",
    "- The centered schemes are accurate for isotropic, or weakly anisotropic models. It becomes terrible as soon as anisotropy exceeds two.\n",
    "- The criss cross scheme is less accurate for isotropic models than the centered scheme, due to grid decoupling which effectively halves the resolution. It becompes more accurate for anisotropy exceeding $2$ typically.\n",
    "- The selling scheme matches the accuracy of the centered scheme for isotropic metrics, and is the best one as soon as anisotropy exceeds 1.6 typically. There admittely is a small regime of weak anisotropy where it is beaten by the centered scheme.\n",
    "\n",
    "The bottom line is that the fourth order Selling scheme is usable at 6ppw with any anisotropy, whereas the centered and criss-cross schemes would require increased sampling density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab0b880a-6446-4f0b-9f6a-57564b4670e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_Acoustic(*result_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697fdd8-2a96-4653-8e96-b20464178f7b",
   "metadata": {},
   "source": [
    "In applications to seismic tomography, with topographic changes of coordinates, the anisotropy is unlikely to exceed $5$.\n",
    "Previous observations still hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b383dc4d-4d67-4e28-a4d5-93cc4519c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_anisos = [κ for κ in result_2d[1].aniso if κ<=5]\n",
    "compare_Acoustic(*result_2d,anisos=small_anisos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b9963-1727-4f26-b021-9376d86afd51",
   "metadata": {},
   "source": [
    "A rule of thumb is to keep numerical dispersion around $10^{-2}$, which is typically achieved using :\n",
    "- 10 points per wavelength for the second order scheme.\n",
    "- 6 points per wavelength for the fourth order scheme.\n",
    "- 4 (?) points per wavelength for the sixth order scheme.\n",
    "\n",
    "Previous observations still hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dea0372f-a888-45bd-a681-b75d4e5612d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,6])\n",
    "plt.subplot(1,2,1); compare_Acoustic(*result_2d,anisos=small_anisos,ppw=10)\n",
    "plt.subplot(1,2,2); compare_Acoustic(*result_2d,anisos=small_anisos,ppw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f42ae-abe8-4a1a-b28d-a2b79f37af65",
   "metadata": {},
   "source": [
    "We previously considered the mean square error on the numerical dispersion. \n",
    "Here we instead consider the worst case scenario instead. \n",
    "Observations : \n",
    "- The Selling scheme is now always best. The small region where it was beaten by the centered scheme, corresponding to weak anisotropy, has disappeared.\n",
    "- The difference between the Selling and criss-cross scheme is a bit smaller than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dfdcbdc-dab9-4f49-b79e-fa821b063350",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_Acoustic(*result_2d,anisos=small_anisos,ord=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c38d668-faa3-4366-97e1-bd23fead165c",
   "metadata": {},
   "source": [
    "The sixth order schemes are a bit of a stretch. Usually, one only consider second and fourth order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8921080d-212b-466f-a995-b91c23780425",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_Acoustic(*result_2d,anisos=small_anisos,ord=np.inf,\n",
    "                 schemes=['centered2','centered4','crisscross2','crisscross4','Selling2','Selling4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d7363-b38d-4484-af53-e97647fbce74",
   "metadata": {},
   "source": [
    "### 1.2 Three dimensions, needle-like anisotropy\n",
    "\n",
    "For simplicity, we'll focus on two types of anisotropies : needle like, and plate like. \n",
    "- needle-like : eigenvalues are $(\\kappa, 1, 1)$, where $\\kappa > 1$. Common in image processing, motion planning, etc\n",
    "- plate-like : eigenvalues are $(1,\\kappa,\\kappa)$, where $\\kappa>1$. Natural in seismic applications, since waves travels faster horizontally than vertically in layered media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd683e7-3e40-48b4-b2ea-792c12f6074f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 633 ms, total: 1.91 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# May take up to a minute to execute\n",
    "result_needle = dispersions(ppw=[6,10],vdim=3,nθ=40,mk_aniso=mk_needle,name=\"Needle-like 3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06194d4a-de6d-4f88-9c5e-a67a938e7b6c",
   "metadata": {},
   "source": [
    "**Needle case**\n",
    "\n",
    "The Selling schemes, and the second order crisscross scheme, do not appear to suffer from anisotropy at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8cc80fd-e1ed-4d2c-931a-dba8bc26eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_Acoustic(*result_needle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f386a-4201-47c9-b468-217e4f0412cd",
   "metadata": {},
   "source": [
    "Very similar conclusions to the two dimensional case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "200c2618-d278-43ee-a6c2-f43b8ea3d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_Acoustic(*result_needle,anisos=small_anisos,ord=np.inf,\n",
    "                 schemes=['centered2','centered4','crisscross2','crisscross4','Selling2','Selling4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9c2c696-5af5-4893-8de9-aacca4d4b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_Acoustic(*result_needle,anisos=small_anisos,ppw=10,\n",
    "                 schemes=['centered2','centered4','crisscross2','crisscross4','Selling2','Selling4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe8ae4-6f5f-47cf-bd86-b73da8b7f29e",
   "metadata": {},
   "source": [
    "### 1.3 Three dimensions, plate-like anisotropy\n",
    "\n",
    "The results are very similar to the two-dimensional and needle-like cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e3f33d9-8ff7-4658-a5c5-a929749fde86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.36 s, sys: 722 ms, total: 2.08 s\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# May take up to a minute to execute\n",
    "def mk_plate(uθ,κ): return Riemann.needle(uθ,κ,1).m\n",
    "result_plate = dispersions(ppw=[6,10],vdim=3,nθ=40,mk_aniso=mk_plate,name=\"Plate-like 3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8972930-39ec-4348-b6f5-22995c5f5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_Acoustic(*result_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0cb8c28-6d28-4316-987e-dfea56d8f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_Acoustic(*result_plate,anisos=small_anisos,ord=np.inf,\n",
    "                 schemes=['centered2','centered4','crisscross2','crisscross4','Selling2','Selling4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6eea216-c1ca-44d2-a17c-3151c941f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional image exports\n",
    "for result in (result_2d,result_needle,result_plate):\n",
    "    for ord in (2,np.inf):\n",
    "        fig = plt.figure()\n",
    "        compare_Acoustic(*result,anisos=small_anisos,ord=ord,schemes=['centered2','centered4','crisscross2','crisscross4','Selling2','Selling4'])\n",
    "        savefig(fig,to_filename(result[1].name)+f\"-{ord=}.png\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc2f57-42b8-4f85-b223-5ae7bc378c5c",
   "metadata": {},
   "source": [
    "## 2. Elastic dispersion\n",
    "\n",
    "Elastic waves have $d$ propagation modes in dimension $d$. We sort them from slowest to fastest. The fastest mode is often referred to as the pressure wave, while the others are shear waves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca24b52-0ed3-4dee-8f84-33b4c304eb97",
   "metadata": {},
   "source": [
    "### 2.1 Two dimensions\n",
    "\n",
    "<!---\n",
    "ϵ=1e-6; ω_exact,_,_ = dispersion_Virieux(ks,ρ,C,ϵ*dx,ϵ*dt,order_x=order_x) # Too lazy\n",
    "#ω_Virieux2,_,_  = dispersion_Virieux(ks,ρ,C,dx,dt,order_x=2)\n",
    "#ω_Virieux4,_,_  = dispersion_Virieux(ks,ρ,C,dx,dt,order_x=4)\n",
    "ω_Lebedev2,_,_  = dispersion_Virieux(ks,ρ,C,dx*np.sqrt(2),dt,order_x=2)\n",
    "ω_Lebedev4,_,_  = dispersion_Virieux(ks,ρ,C,dx*np.sqrt(2),dt,order_x=4)\n",
    "\n",
    "#ω_Selling2,_,_  = dispersion_e(ks,af(ρ),af(C),dx,dt,order_x=2,order_t=2)\n",
    "#ω_Selling4,_,_  = dispersion_e(ks,af(ρ),af(C),dx,dt,order_x=4,order_t=2)\n",
    "ω_Selling2_corr,_,_  = dispersion_SellingCorrelated(ks,af(ρ),af(C),dx,dt,order_x=2)\n",
    "ω_Selling4_corr,_,_  = dispersion_SellingCorrelated(ks,af(ρ),af(C),dx,dt,order_x=4)\n",
    "\n",
    "ω_Selling2_stag,_,_ = dispersion_SellingStaggered2(ks,ρ,C,dx,dt,order_x=2)\n",
    "ω_Selling4_stag,_,_ = dispersion_SellingStaggered2(ks,ρ,C,dx,dt,order_x=4)\n",
    "\n",
    "ω_Selling2_stagExt,_,_ = dispersion_SellingStaggered2(ks,ρ,C,dx,dt,order_x=2,decomp=staggered_decomp_linprogExt)\n",
    "ω_Selling4_stagExt,_,_ = dispersion_SellingStaggered2(ks,ρ,C,dx,dt,order_x=4,decomp=staggered_decomp_linprogExt)\n",
    "\n",
    "ω_Selling2_mystagExt,_,_ = dispersion_SellingStaggered2(ks,ρ,C,dx,dt,order_x=2,decomp=mydecomp)\n",
    "ω_Selling4_mystagExt,_,_ = dispersion_SellingStaggered2(ks,ρ,C,dx,dt,order_x=4,decomp=mydecomp)\n",
    "\n",
    "#ω_Selling,_,_  = dispersion_e(ks,af(ρ),af(C),dx,dt,order_x=6,order_t=2) # Order 6 does not bring much benefit\n",
    "#ω_cont,_ = Hooke(Cs).waves(ks,ρs) #lp.dot_VAV(ks,Ds,ks)/ρs\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "067eb358-08e7-408b-96ac-4d95f94152ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion_exactElastic(k,ρ,C): \n",
    "    shape = tuple(np.maximum(k.shape[1:],C.shape[2:]))\n",
    "    k = np.broadcast_to(k,(*k.shape[:1],*shape))\n",
    "    C = np.broadcast_to(C,(*C.shape[:2],*shape))\n",
    "    ω2 = np.moveaxis(np.linalg.eigvalsh(np.moveaxis(Hooke(C/ρ).contract(k),(0,1),(-2,-1))),-1,0)\n",
    "    return np.sqrt(ω2)\n",
    "#    return Hooke(C).waves(k,ρ)[0]\n",
    "def dispersion_Lebedev(k,ρ,C,dx,dt,order_x):\n",
    "    s2 = 2**(1-1/len(k))\n",
    "    return ec.dispersion_Virieux(k,ρ,C,dx*s2,dt,order_x)\n",
    "def dispersion_SellingStaggeredExt2(k,ρ,C,dx,dt,order_x): \n",
    "    return ec.dispersion_SellingStaggered2(k,ρ,C,dx,dt,order_x,decomp=ec.staggered_decomp_linprogExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c95ed630-40d3-493e-85f1-5b507d2db7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_elastic_Thomsen2 = {\n",
    "    'aniso':list(Thomsen.ThomsenData.keys())+['mica','olivine','stishovite'], # Anisotropy types\n",
    "    'ppw':[6,10], #[3,4,5,6,8,10,12,15], # Points per wavelength\n",
    "\n",
    "    'scheme':['Virieux2','Virieux4','Lebedev2','Lebedev4','Selling2','Selling4','Selling6',\n",
    "              'Selling_corr2','Selling_corr4','Selling_corr6','Selling_stag2','Selling_stag4','Selling_stagExt2','Selling_stagExt4'],\n",
    "    'style':[':',':', '--','--', '-','-','-', '-.','-.','-.', 'o','o', 'x','x'], # Plot style, and color below\n",
    "    'color':['blue','cyan', 'green','olive', 'red','orange','brown', 'red','orange','brown', 'pink','purple', 'pink','purple'],\n",
    "    'dispersion':[*(ec.dispersion_Virieux,)*2,*(dispersion_Lebedev,)*2,*(how.dispersion_e,)*3,*(ec.dispersion_SellingCorrelated,)*3,\n",
    "                 *(ec.dispersion_SellingStaggered2,)*2,*(dispersion_SellingStaggeredExt2,)*2],\n",
    "    'dispersion_exact':dispersion_exactElastic,\n",
    "    'decomp':(lambda D:Hooke(D).Selling()), 'use_decomp':(False,)*4+(True,)*6+(False,)*4, # Precompute Selling decomposition\n",
    "\n",
    "    'ord':(1,2,np.inf), # norm order for the relative error \n",
    "    'ω_ref':'geom', # Alternatively : 'max', 'min', None\n",
    "    'dt':1e-4, # Vanishingly small : only interested in spatial dispersion here\n",
    "\n",
    "    'nθ':60,'prune':False, # Angular discretization \n",
    "    'vdim':2,\n",
    "    'mk_aniso':None, 'name':None, 'mode':None, # To fill\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "847617a5-af3b-4642-b404-cd1e0ce2b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hooke_vti_rotate(uθ,hk):\n",
    "    rot = rotation_params(uθ) # vdim==2 : angle. vdim==3 : angle and axis\n",
    "    return (hk.rotate_by(rot) if len(uθ)==2 else hk.rotate_by(*rot)).hooke # Rotate and export\n",
    "    \n",
    "def mk_Thomsen(uθ,name):\n",
    "    \"\"\"Rotate the elastic material designed by name, so that the vertical axis is uθ\"\"\"\n",
    "    if name in Thomsen.ThomsenData: hk = Hooke.from_ThomsenElastic(Thomsen.ThomsenData[name])[0] # Thomsen materials\n",
    "    else: hk = {'mica':Hooke.mica, 'olivine':Hooke.olivine, 'stishovite':Hooke.stishovite}[name][0]\n",
    "    if len(uθ)==2: hk = hk.extract_xz()\n",
    "    hk.hooke/=np.max(hk.hooke) # Normalize\n",
    "    return hooke_vti_rotate(uθ,hk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c981629-ffdc-4c9a-8cce-33c123884318",
   "metadata": {},
   "source": [
    "The next two cells may take a minute to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4207079c-1621-4ed3-94bd-56322992c7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 331 ms, total: 1.54 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_pressure_Thomsen2 = dispersions(default=params_elastic_Thomsen2,mk_aniso=mk_Thomsen,name='Pressure Thomsen 2d',mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68f71799-b2e1-43e0-82c8-808f6da96786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-mariemirebeau/Dropbox/Programmes/GithubM1/AdaptiveGridDiscretizations/Notebooks_Repro/../../AdaptiveGridDiscretizations/agd/ExportedCode/Notebooks_Div/ElasticComparisons.py:630: RuntimeWarning: invalid value encountered in sqrt\n",
      "  Iω = np.sqrt(Iω2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 300 ms, total: 1.49 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_shear_Thomsen2 = dispersions(default=params_elastic_Thomsen2,mk_aniso=mk_Thomsen,name='Shear Thomsen 2d',mode=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d010d33f-20dd-4535-82ba-3da935137789",
   "metadata": {},
   "source": [
    "Not sure how to plot these results. We can first look at how often each scheme is first. Or compare to the reference dispersion, e.g. Lebedev ? Likely better to compare within a given order class, or stencil width.\n",
    "\n",
    "We may also want to sort the materials by difficulty. Based e.g. on the dispersion of the Lebedev scheme ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77159d9f-f376-4b86-ba2c-0494e5936cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_elastic_Thomsen(result,params,ppw=6,ord=2,anisos=None,schemes=None,styles=None):\n",
    "    ippw = list(params.ppw).index(ppw)\n",
    "    iord = list(params.ord).index(ord)\n",
    "    ianiso = [list(params.aniso).index(aniso) for aniso in anisos] if anisos else np.arange(len(params.aniso))\n",
    "    ischeme = [list(params.scheme).index(scheme) for scheme in schemes] if schemes else np.arange(len(params.scheme))\n",
    "    if styles is None: styles = [params.style[i] for i in ischeme]\n",
    "    \n",
    "    plt.title(f\"{params.name} dispersions, {ppw=}, {ord=}\")\n",
    "    plt.ylabel(\"Dispersion error\")\n",
    "    plt.xlabel(\"Anisotropic material\")\n",
    "    ax = params.aniso if isinstance(params.aniso,np.ndarray) else np.arange(len(params.aniso))\n",
    "    for i,style in zip(ischeme,styles):\n",
    "        plt.semilogy(ax,result[ippw,i,iord,ianiso],style,color=params.color[i],label=params.scheme[i])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd6b22-1f41-4de2-b7bf-0f1c4c7d0aab",
   "metadata": {},
   "source": [
    "Looking at the pressure wave data : \n",
    "- The Selling schemes, from best to worst, appear to be usually : correlated, standard, staggered, staggered_ext.\n",
    "- There are a few circumstances in which the order is reversed. In particular, the staggered schemes are better for pressure and order two.\n",
    "- The Selling schemes have annoying spikes in anisotropy. The spikes can also be seen in the Virieux and Lebedev schemes, but are much less strong.\n",
    "- The spikes are a little less strong with the correlated scheme.\n",
    "  \n",
    "We should figure out what causes these spikes. (Type of material, Selling offsets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86774848-cc48-4991-8e06-ae0206839f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "result = result_pressure_Thomsen2\n",
    "compare_elastic_Thomsen(*result,ppw=6)\n",
    "savefig(fig,to_filename(result[1].name)+'-all.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f77d1-6822-4ec4-bbf3-66d2a1cfe565",
   "metadata": {},
   "source": [
    "Looking at the shear wave data.\n",
    "\n",
    "We have the following observations:\n",
    "- we often beat the non-existing Virieux scheme, for mildly anisotropic materials.\n",
    "- There are some very pronounced spikes, for very anisotropic materials.\n",
    "\n",
    "Among Selling schemes : \n",
    "- *fourth order*, from best to worst : correlated, standard, staggered, staggered ext. However there are more inversions than for the pressure wave, and staggered is often better.\n",
    "- *second order*, from best to worts : staggered, staggered ext, correlated, standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3be15eae-b1c2-4e3d-9d59-9477c932ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "result = result_shear_Thomsen2\n",
    "compare_elastic_Thomsen(*result,ppw=6)\n",
    "savefig(fig,to_filename(result[1].name)+'-all.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9c520-a9b8-4b2a-821b-72fdddd7759a",
   "metadata": {},
   "source": [
    "Let us try to figure out what type of material is creating these bad spikes, defavorable to the Selling schemes.\n",
    "If we focus on the fourth order schemes, which appear to be most popular, the bad guys are mostly crystals.\n",
    "\n",
    "In other words, our schemes suffer from strong anisotropy, which is a bit surprising in view of the acoustic results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b76646a-5166-424e-a21c-cad7b65a2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad materials 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Wills Point shale - 1',\n",
       " 'Muscovite crystal',\n",
       " 'Biotite crystal',\n",
       " 'Aluminium-lucite composite',\n",
       " 'Gypsum-weathered material',\n",
       " 'mica']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iLebedev = params_elastic_Thomsen2['scheme'].index('Lebedev4')\n",
    "iSelling_corr = params_elastic_Thomsen2['scheme'].index('Selling_corr4')\n",
    "ippw = 0 # 6 ppw\n",
    "iord = 1 # L^2 err\n",
    "res = result_shear_Thomsen2[0][ippw,:,iord,:] \n",
    "bad = res[iLebedev]<res[iSelling_corr]\n",
    "print(f\"Number of bad materials {np.sum(bad)}\")\n",
    "bad_materials = [params_elastic_Thomsen2['aniso'][i] for i,b in enumerate(bad) if b]\n",
    "bad_materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96c15c3c-7511-42ac-9b68-ceaeae4dcc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional image exports\n",
    "for result in (result_pressure_Thomsen2,result_shear_Thomsen2):\n",
    "    for ord in (2,np.inf):\n",
    "        fig = plt.figure(figsize=[14,6])\n",
    "        compare_elastic_Thomsen(*result,ord=ord,schemes=('Lebedev2','Lebedev4','Selling_corr2','Selling_corr4'),\n",
    "                                styles=[':',':','-','-'],ppw=10)\n",
    "        savefig(fig,to_filename(result[1].name)+f\"-Leb-corr-{ord=}.png\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864fdb4-d71d-4ce9-9c2a-32ff9c847951",
   "metadata": {},
   "source": [
    "### 2.2 Two dimensions, deformed materials\n",
    "\n",
    "Some anisotropy arises naturally, by the chemical structure of the material. But in other contexts anisotropy arises artificially from changes of coordinates in the domain. \n",
    "\n",
    "Here we try to looke at the dependency of the dispersion to this type of anisotropy. \n",
    "\n",
    "**Coefficients of the deformed elastic wave equation.**\n",
    "Changes of coordinates affect several coefficients in the elastic wave equation:\n",
    "- the hooke tensor, as considered here.\n",
    "- the symmetric positive definite matrix related to the kinetic energy. It is *not considered here*, and as a result the dispersion relation is *inexact*. \n",
    "- a low order additive term to the strain tensor, which only arises for non-linear changes of coordinates, and is not considered here.\n",
    "\n",
    "Correct theoretical and numerical dispersion relations with anisotropic kinetic energy are doable but require a bit more work.\n",
    "\n",
    "**Effect on the Hooke tensor.**\n",
    "In the current state, material deformations appears *very bad* for the Selling schemes. The underlying reason is the following : define the anisotropy ratio\n",
    "$$\n",
    "    \\mu(D) := \\sqrt{\\lambda_{\\max}(D)/\\lambda_{\\min}(D)}\n",
    "$$\n",
    "of a symmetric positive definite matrix. Consider now a physical material to which a dilation $\\kappa_*$ is applied along some axis. Then : \n",
    "- In the acoustic case, anisotropy $\\mu(D_*)\\approx \\kappa_*$ of the resulting tensor scales linearly with $\\kappa_*$.\n",
    "- In the elastic case, the Hooke tensor anisotropy $\\mu(C_*) \\approx \\kappa_*^2$ scales quadratically with $\\kappa_*$.\n",
    "\n",
    "The Selling offsets, on the other hand, sale approximately linearly with the tensor anisotropy $\\mu(D_*)$ or $\\mu(C_*)$. \n",
    "This means that the Selling schemes will use excessively large offsets, as soon as anisotropy is a bit pronounced, which strongly degrades their effective accuracy.\n",
    "\n",
    "All the Selling schemes are subject to this behavior. \n",
    "- The staggered schemes quickly become undefined, because we only classified a few vertices of the equivalent linear program. The other schemes remain well defined, but dispersion becomes horrendous.\n",
    "- High order schemes do not really help, and sometimes even degrade the situation.\n",
    "\n",
    "The bottom line is that the Selling schemes should likely be rejected for distortions with anisotropy ratios $\\geq 2$. Sadly, no extreme anisotropy can be envisionned, contrary to the acoustic case. For weaker deformations, they remain usable. \n",
    "\n",
    "<!---\n",
    "Erroneous comments, from when pressure and shear modes were exchanged.\n",
    "- The only positive point is that the pressure wave seems worse than the shear wave (In applications, the shear wave dispersion is limiting, since the corresponding wavelength is shorter). In the shear case, the correlated Selling scheme remains competitive with Lebedev up to anisotropy ratios $\\approx 5$.\n",
    "\n",
    " taking into account that the shear wave dispersion is the bottlenect,\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e92f251-b9fc-4110-9881-c60271fc0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_elastic_needle2 = params_elastic_Thomsen2.copy()\n",
    "params_elastic_needle2['aniso']=np.array([1,1.2,1.5,2,2.5,3,4,5,6]) # Deformation ratios # 8,10,13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3115fc99-d612-405f-9460-4365cc526ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_ref = Hooke.stishovite[0].extract_xz()\n",
    "hk_ref.hooke/=np.max(hk_ref.hooke)\n",
    "def mk_elastic_needle(uθ,κ):\n",
    "    \"\"\"Deform the elastic medium, with 1/κ along horizontal axis, then rotate.\"\"\"\n",
    "    diag = np.diag((κ,)+(1,)*(len(uθ)-1))\n",
    "    return hooke_vti_rotate(uθ,hk_ref.rotate(diag)) # Not actually a rotation...\n",
    "def mk_elastic_plate(uθ,κ):\n",
    "    \"\"\"Deform the elastic medium, with 1/κ along horizontal axis, then rotate.\"\"\"\n",
    "    diag = np.diag((1,)+(κ,)*(len(uθ)-1))\n",
    "    return hooke_vti_rotate(uθ,hk_ref.rotate(diag)) # Not actually a rotation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8490ca14-ca90-48f8-a8c0-567aed2bdb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17548119783512647, 0.013088255355702327)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uθ = np.array((1.,0))\n",
    "hk = mk_elastic_needle(uθ,10)\n",
    "Hooke(hk).norm(uθ),Hooke(hk).norm(lp.perp(uθ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08edbbdf-6f5d-4f93-9432-03d01ecb9468",
   "metadata": {},
   "source": [
    "Here we can see that a deformation by a factor $10$ along one axis, implies a ratio $\\approx 10^4$ on the eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe4f5619-aa79-4721-bd77-609e61ea17c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.82754055e-01, 3.24742268e+01, 5.83774611e+03])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvalsh(mk_elastic_needle((1,0),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40ca2af9-ab1a-4d72-9cd6-66f4595b2c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 212 ms, sys: 42.4 ms, total: 255 ms\n",
      "Wall time: 256 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_pressure_needle2 = dispersions(default=params_elastic_needle2,mk_aniso=mk_elastic_needle,name='Pressure needle 2d',mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5b87fd5-e049-4570-b4b0-14c756376410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 197 ms, sys: 39.9 ms, total: 237 ms\n",
      "Wall time: 238 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_shear_needle2 = dispersions(default=params_elastic_needle2,mk_aniso=mk_elastic_needle,name='Shear needle 2d',mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4589bb-b597-4aa2-b78b-2a8ff16c0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[14,6])\n",
    "result = result_pressure_needle2\n",
    "compare_elastic_Thomsen(*result,ppw=10)\n",
    "savefig(fig,to_filename(result[1].name)+\"-all.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73fae4-7765-46de-a0a8-fcd24379c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[14,6])\n",
    "result = result_shear_needle2\n",
    "compare_elastic_Thomsen(*result) \n",
    "savefig(fig,to_filename(result[1].name)+\"-all.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77cb73d-9c81-4282-9aba-523de3fb07ee",
   "metadata": {},
   "source": [
    "**Additional image exports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec87c7-0394-4802-9352-c6e0a4f307ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in (result_pressure_needle2,result_shear_needle2):\n",
    "    for ord in (2,np.inf):\n",
    "        fig = plt.figure(figsize=[14,6])\n",
    "        compare_elastic_Thomsen(*result,ord=ord,schemes=('Lebedev2','Lebedev4','Selling_corr2','Selling_corr4'),styles=[':',':','-','-'])\n",
    "        savefig(fig,to_filename(result[1].name)+f\"-Leb-corr-{ord=}.png\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16472c-1ebc-44c2-a058-5021c9e9c338",
   "metadata": {},
   "source": [
    "### 2.3 Three dimensions\n",
    "\n",
    "In three dimensions, only the standard variant of the elastic scheme is currently implemented. \n",
    "Implementing the correlated variant should not be too hard. The staggered variants are more complicated to generalize, but in view of the previous results there is no need to rush.\n",
    "\n",
    "<!---\n",
    "Over the 52 orientations, there are only a few that raise issues typically. We prune them out.\n",
    " #,prune=True)\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65839ab3-c579-4e15-b437-70b8200579c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uθ,_,_ = vti_orientations(40,3)\n",
    "bad_decomp = []\n",
    "for name in params_elastic_Thomsen2['aniso']:\n",
    "    C = mk_Thomsen(uθ,name)\n",
    "    λ,e = Eikonal.VoronoiDecomposition(C)\n",
    "    bad_λ = np.any(np.isnan(λ),axis=0)\n",
    "    if np.any(bad_λ): \n",
    "        bad_decomp.append((name,np.sum(bad_λ)))\n",
    "        print(np.nonzero(bad_λ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464e454-9bcf-4ba0-99bb-d52a61fbbe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(bad_decomp)==0\n",
    "# 6D Voronoi decomposition was fixed by adding a tolerance for the positivity of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca0e28-bbb8-4864-860d-d1ca99784fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_elastic_Thomsen3 = params_elastic_Thomsen2.copy()\n",
    "params_elastic_Thomsen3.update({\n",
    "    'nθ':20, # 40, yields 13 min computation time, accuracy not much improved\n",
    "    'vdim':3,\n",
    "    'aniso':[name for name in params_elastic_Thomsen2['aniso'] if name not in bad_decomp],\n",
    "    'dispersion':params_elastic_Thomsen2['dispersion'][:10],\n",
    "    'scheme':params_elastic_Thomsen2['scheme'][:10],\n",
    "    'prune':True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659449c7-7dd9-40da-ae8d-646d57027878",
   "metadata": {},
   "source": [
    "The following cells take a minute to execute each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acadd8b0-29ab-486b-a12a-fd92717bed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_pressure_Thomsen3 = dispersions(default=params_elastic_Thomsen3,mk_aniso=mk_Thomsen,name='Pressure Thomsen 3d',mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290070a-79f6-4b17-a638-aea2d79460d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_shear1_Thomsen3 = dispersions(default=params_elastic_Thomsen3,mk_aniso=mk_Thomsen,name='Fast shear Thomsen 3d',mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0fb4f-73f1-4f55-8092-e93a34fb9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_shear0_Thomsen3 = dispersions(default=params_elastic_Thomsen3,mk_aniso=mk_Thomsen,name='Slow shear Thomsen 3d',mode=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4d377-2cb5-450b-94ba-2a0eed9a0781",
   "metadata": {},
   "source": [
    "The situation is more or less comparable to the two dimensional case : the Selling scheme is usually better than the Lebedev scheme, except for a few crystals where the dispersion spikes. \n",
    "\n",
    "The correlated scheme improves things a bit:\n",
    "- mostly for the pressure wave, not as much for the shear waves.\n",
    "- the improvement is less strong than in two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de27c8-cdf4-454c-be56-f5ac5cf6a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[14,6])\n",
    "compare_elastic_Thomsen(*result_pressure_Thomsen3)\n",
    "savefig(fig,\"Pressure-Thomsen-3d-all.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4fd091-743c-47cc-b1e7-36dcbed9c29b",
   "metadata": {},
   "source": [
    "From the dispersion relations of the shear waves, we observe that:\n",
    "- Spikes are a bit less hard on the shear waves.\n",
    "- The Selling scheme is on par with the Virieux scheme for the first shear wave, but somewhat worse for the slowest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8be4a-b9b1-42ce-9826-3ac7f1a483a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[14,6])\n",
    "compare_elastic_Thomsen(*result_shear1_Thomsen3)\n",
    "savefig(fig,\"Shear1-Thomsen-3d-all.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc26985-804a-4219-bd1c-377e8cc2e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[14,6])\n",
    "compare_elastic_Thomsen(*result_shear0_Thomsen3)\n",
    "savefig(fig,\"Shear0-Thomsen3d-all.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c2b85-45f6-43f5-afa4-18c481a9f004",
   "metadata": {},
   "source": [
    "**Saving a few additional figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881b631-a9d2-4276-8318-81f93ce302ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in (result_pressure_Thomsen3,result_shear1_Thomsen3,result_shear0_Thomsen3):\n",
    "    for ord in (2,np.inf):\n",
    "        fig = plt.figure(figsize=[14,6])\n",
    "        compare_elastic_Thomsen(*result,ord=ord,schemes=('Lebedev2','Lebedev4','Selling_corr2','Selling_corr4'),styles=[':',':','-','-'])\n",
    "        savefig(fig,to_filename(result[1].name)+f\"-Leb-corr-{ord=}.png\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e087df36-b28e-4a6e-8a56-5d58ab02b466",
   "metadata": {},
   "source": [
    "### 2.4 Three dimensions, deformed materials\n",
    "\n",
    "This subsection is *todo*, but first we should obtain the correct dispersion relations under changes of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e49817-151b-4502-936e-c57a8f0deaf6",
   "metadata": {},
   "source": [
    "## 3. Exact solutions in inhomogeneous domains\n",
    "\n",
    "We compare the accuracy of the two dimensional schemes for acoustic and elastic wave equations. For that purpose, we design a synthetic test case with periodic boundary conditions and an exact solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0d85b-d252-41aa-b7c8-1a18fbd7661a",
   "metadata": {},
   "source": [
    "### 3.1 Domain deformation\n",
    "\n",
    "The synthetic inhomogeneous test case is obtained as a diffeomorphic deformation of a homogeneous domain. \n",
    "The chosen deformation is smooth, periodic, and otherwise rather arbitrary. A parameter allows to tune the strength of the deformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c73d37d-1157-4cff-844d-1432b3e90979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ϕ_default(X,ϵ=0.05): \n",
    "\t\"\"\"Some perturbation of the identity map on the torus (R/Z)^2. Appears to be invertible when ϵ<=0.05\"\"\"\n",
    "\tx,y = X\n",
    "\treturn ad.array([x + 0.6*ϵ*np.sin(2*π*(x+2*y)+2) + ϵ*np.sin(2*π*x), \n",
    "\t\t\t\t\t y - ϵ*np.exp(np.cos(2*π*(x-y))) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5996e-592c-4463-83b9-f3725e7e60cf",
   "metadata": {},
   "source": [
    "In order to visualize the deformation, we apply it to a regular grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294cec5-6c3d-4e8d-8337-54628c6cd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,6])\n",
    "for i,ϵ in enumerate((0.02,0.05)):\n",
    "    plt.subplot(1,2,1+i)\n",
    "    plt.title(f\"Deformed medium, {ϵ=:.2f}\")\n",
    "    X,dx = how.make_domain(20,2)\n",
    "    plt.scatter(*ϕ_default(X,ϵ))\n",
    "    plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530b963-a428-4582-b791-c5a9a18e7229",
   "metadata": {},
   "source": [
    "The singular values of the jacobian quantify the amount of distorsion. A substantial deformation already occurs for $\\epsilon=0.02$, with a ratio $\\approx 1.66$ of the dilations along orthogonal axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e38ccb-d1fc-4966-a032-aca710cead9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ad = ad.Dense.identity(constant=X,shape_free=(2,))\n",
    "for ϵ in (0.01,0.02,0.05):\n",
    "    dϕ = ϕ_default(X_ad,ϵ).gradient()\n",
    "    S = np.moveaxis(np.linalg.svd(np.moveaxis(dϕ,(0,1),(-2,-1))).S,-1,0)\n",
    "    print(f\"Max deformation ratio for {ϵ=:.2f} : \", np.max(S[0]/S[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d149d2-5aaa-4cdc-8120-452429fa70d0",
   "metadata": {},
   "source": [
    "### 3.2 Planewaves in the homogeneous domain\n",
    "\n",
    "The exact solution in the inhomogeneous deformed domain is obtained, appropriately, as a diffeomorphic deformation of an exact solution in the original homogeneous domain.\n",
    "The latter is defined as a sum of planewaves, in all directions, with random phases and amplitudes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fccf2-2ad6-4f90-b19d-0c808ef44dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_cos():\n",
    "\t\"\"\"Returns a cosine-like 1-periodic function with a random phase and amplitude.\"\"\"\n",
    "\tamplitude, phase = np.random.rand(2)\n",
    "\treturn lambda s : amplitude*np.cos(2*π*(s+phase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d345f-9888-490e-ac1d-22692a5483ce",
   "metadata": {},
   "source": [
    "Planewaves in all directions, with random amplitudes, phases, and propagation modes in the elastic case. \n",
    "\n",
    "*Periodicity.* The modulating functions are $1$-periodic, rather than $2\\pi$ periodic. The variable `kr` below stands for *reduced wave number*, and the actual wavenumber is $2 \\pi \\times$ `kr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344ce9e-4063-4728-b57f-cdcb217a5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "krs = [(i,j) for i in range(-2,3) for j in range(-2,3) if not (i in (-2,0,2) and j in (-2,0,2))]\n",
    "planewaves_default_a = [ (kr, rand_cos() ) for kr in krs]\n",
    "planewaves_default_e = [ (kr, rand_cos(), mode) for kr in krs for mode in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a3f44-d755-4039-a6a2-faec27d749f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planewave_with_spatial_frequency(Nwaves,planewave):\n",
    "\t\"\"\"Adjust the number of oscillations in a planewave, within the domain [-1,1]^d, retaining periodicity\"\"\"\n",
    "\tkred,fun = planewave[:2]\n",
    "\treturn (kred,lambda s:fun(s*np.floor(Nwaves/np.linalg.norm(kred))))+planewave[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416f971-4203-4ad6-b471-07c81724161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nwaves = 8\n",
    "Nx=100\n",
    "X,dx = how.make_domain(Nx,2)\n",
    "kr,f = planewave_with_spatial_frequency(Nwaves,planewaves_default_a[0])\n",
    "plt.contourf(*X,f(kr[0]*X[0]+kr[1]*X[1]))\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485aaae3-c467-4479-b15d-a731ce607e77",
   "metadata": {},
   "source": [
    "### 3.3 Inhomogeneous parameters and exact solution\n",
    "\n",
    "The transformations of the coefficients and solution associated to a domain diffeomorphism are described in detail in [the notebook on high order schemes for wave equations](../Notebook_Div/HighOrderWaves.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4c428-24d1-470a-994b-46a645984f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_a(ρ_flat,D_flat,X,dx, ϕ=ϕ_default):\n",
    "    \"\"\"Parameters and exact solution of the acoustic wave equation in a deformed homogeneous domain\"\"\"\n",
    "    from agd.ExportedCode.Notebooks_Div.HighOrderWaves import ExactSol_a,tq_a,tp_a,tρ_a,tD_a\n",
    "    ϕ,dϕ,inv_dϕ,Jϕ,d2ϕ = how.differentiate(lambda x:ϕ(x),X)\n",
    "    ρ = tρ_a(lambda x:ρ_flat,ϕ,Jϕ)\n",
    "    D = tD_a(lambda x:D_flat,ϕ,inv_dϕ,Jϕ)\n",
    "    def make_sol(planewaves=planewaves_default_a):\n",
    "        \"\"\"Exact homogeneous planewave solution, deformed by ϕ.\"\"\"\n",
    "        q_flat,p_flat = ExactSol_a(ρ_flat,D_flat,*zip(*planewaves))\n",
    "        def q(t): return tq_a(lambda x:q_flat(t,x),ϕ)\n",
    "        def p(t): return tp_a(lambda x:p_flat(t,x),ϕ,Jϕ)\n",
    "        return q,p\n",
    "    return ρ,D,make_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9962885-f6f1-4324-9c8f-5bc1aa6c9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_e(M_flat,C_flat,X,dx, ϕ=ϕ_default): \n",
    "    \"\"\"Parameters and exact solution of the elastic wave equation in a deformed homogeneous domain\"\"\"\n",
    "    from agd.ExportedCode.Notebooks_Div.HighOrderWaves import ExactSol_e,tq_e,tp_e,tM_e,tC_e,tS_e\n",
    "    ϕ,dϕ,inv_dϕ,Jϕ,d2ϕ = how.differentiate(lambda x:ϕ(x),X)\n",
    "    M = tM_e(lambda x:M_flat,ϕ,dϕ,Jϕ)\n",
    "    C = tC_e(lambda x:C_flat,ϕ,inv_dϕ,Jϕ)\n",
    "    vdim=len(X); S_flat = np.zeros((vdim,vdim,vdim))\n",
    "    S = tS_e(lambda x:S_flat,ϕ,dϕ,inv_dϕ,d2ϕ)\n",
    "    def make_sol(planewaves=planewaves_default_e):\n",
    "        \"\"\"Exact homogeneous planewave solution, deformed by ϕ.\"\"\"\n",
    "        q_flat,p_flat = ExactSol_e(M_flat,C_flat,*zip(*planewaves))\n",
    "        def q(t): return tq_e(lambda x:q_flat(t,x),ϕ,dϕ)\n",
    "        def p(t): return tp_e(lambda x:p_flat(t,x),ϕ,inv_dϕ,Jϕ)\n",
    "        return q,p\n",
    "    return M,C,S,make_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866bd63-1b5c-4fd0-8a98-c864226488b4",
   "metadata": {},
   "source": [
    "**Acoustic test case with strong anisotropy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345759f-d4bb-471b-871c-292dc1d98661",
   "metadata": {},
   "outputs": [],
   "source": [
    "ϕ_acoustic = lambda X:ϕ_default(X,0.05)\n",
    "ρ_flat = 1.\n",
    "D_flat = Riemann.from_diagonal([3**2, 1]).rotate_by(π/8).m\n",
    "Nx = 150\n",
    "X,dx = how.make_domain(Nx,2)\n",
    "ρ,D,_ = make_test_a(ρ_flat,D_flat,X,dx,ϕ_acoustic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b85caf-dbfc-4140-a9a9-d496c76f3c52",
   "metadata": {},
   "source": [
    "Because of the strong anisotropy, the linear decomposition presented in [the notebook on Selling's decomposition](../Notebooks_Div/TensorSelling.ipynb) has negative coefficients already for the homogeneous medium (without additional deformation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6302fa3-cae4-4b17-9746-23084a66b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.linear_decomp(D_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a8b8a-46a5-44cb-b656-bed2d1de2398",
   "metadata": {},
   "source": [
    "Furtunately the tensor field is sufficiently smooth for applying the deconvolution method. (I.e. the deconvolved field remains positive definite.) Note that the number of positive coefficients exceeds the Selling case ($3$ coefficients).\n",
    "\n",
    "*Deconvolution width parameter $\\sigma$ (measured in pixels).*\n",
    "Here we need to reduce the value of this parameter, to ensure that the deconvolved matrices remain positive definite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c7368-fc12-4972-baf0-27aebb10f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "λ,e = ts.conv_decomp(*ts.deconv(D,σ=2.5,depth=2)) # Always use depth=2 \n",
    "print(f\"Maximum number of positive coefficients {len(λ)}\")\n",
    "print(f\"Average number of positive coefficients {np.mean(np.sum(λ>0,axis=0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0b762-95a1-44f2-bfcf-467193f4dae1",
   "metadata": {},
   "source": [
    "Compare with the smooth variant of Selling's two-dimensional decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0bd207-e50b-4278-a610-b9f37ab5933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "λ,e = Eikonal.VoronoiDecomposition(D,smooth=True) # Always use depth=2 \n",
    "print(f\"Maximum number of positive coefficients {len(λ)}\")\n",
    "print(f\"Average number of positive coefficients {np.mean(np.sum(λ>0,axis=0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702e015-59e2-46ae-9b7a-68a61ca487ff",
   "metadata": {},
   "source": [
    "**Elastic test case with mild anisotropy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b48b7b-b0da-429c-a21b-5931ba57a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ϕ_elastic = lambda X:ϕ_default(X,0.01)\n",
    "M_flat = np.eye(2)\n",
    "C_flat = Hooke.olivine[0].extract_xz().rotate_by(π/8).hooke; C_flat/=np.max(C_flat)\n",
    "Nx = 150\n",
    "X,dx = how.make_domain(Nx,2)\n",
    "M,C,_,_ = make_test_e(M_flat,C_flat,X,dx,ϕ_elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaadab3-3444-4789-a8de-820ccc555751",
   "metadata": {},
   "source": [
    "Again the, the linear decomposition is already non-positive in the homogeneous medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ae2fa-242f-44b1-95f5-b2e7475933ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.linear_decomp(C_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56b9ba6-607b-4995-a7c9-9c355daa29c6",
   "metadata": {},
   "source": [
    "Since `ϕ_elastic` is smoother than `ϕ_acoustic`, in view of the smaller parameter $\\epsilon$, we can increase the size of the convolution support $\\sigma$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8951e29-1cfe-4941-9089-fdf4f10e719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "λ,e = ts.conv_decomp(*ts.deconv(C,σ=5,ϵ=2e-4,depth=2)) \n",
    "print(f\"Maximum number of positive coefficients {len(λ)}\")\n",
    "print(f\"Average number of positive coefficients {np.mean(np.sum(λ>0,axis=0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea56d6c-2252-4fc4-bc60-b75a57c11f3e",
   "metadata": {},
   "source": [
    "Compare with the smooth variant of Selling's decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bccb64-844c-4684-9d9a-af4ea52bee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "λ,e = Eikonal.VoronoiDecomposition(C,smooth=True)\n",
    "print(f\"Maximum number of positive coefficients {len(λ)}\")\n",
    "print(f\"Average number of positive coefficients {np.mean(np.sum(λ>0,axis=0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0876e-fcb5-4429-8c2d-1002b5509493",
   "metadata": {},
   "source": [
    "### 3.4 Acoustic accuracy comparison\n",
    "\n",
    "We compare the accuracy of different schemes for the acoustic wave equation. Time integration relies on the Euler symplectic method, which is second order in time if viewed with the appropriate half-step time shifts.\n",
    "\n",
    "**Scheme order in space.** \n",
    "Staggered schemes are implemented up to order 4, whereas centered schemes are implemented up to order 6. \n",
    "(Note : in the one dimension case, a staggered scheme of order 4, and a centered scheme of order 6, both yield a 7 point finite difference approximation of the laplacian.)\n",
    "\n",
    "**Points per wavelength (ppw).** \n",
    "The given number of points per wavelength assumes no domain deformation. It should be regarded as an average value. The local number of ppw depends on the distortion induced by the diffeomorphism, which can be significant. \n",
    "\n",
    "**Smooth variants of Selling's decomposition.**\n",
    "The standard Selling scheme are very accurate for low ppw. However, for high ppw, in the $L^\\infty$ norm, it does not appear to converge at the expected order (consistency order of the Hamiltonian discretization). This is likely due to the non-smoothness of the coefficients, and it is why we also consider variants of Selling's decomposition with smooth coefficients for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281b621-6743-4f40-9da8-112426340563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ϵ_acoustic = 0.05; ϕ_acoustic = lambda X:ϕ_default(X,ϵ_acoustic)\n",
    "ρ_flat = 1.\n",
    "D_flat = Riemann.from_diagonal([3**2, 1]).rotate_by(π/8).m\n",
    "Nt = 100 # Number of time steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233c9be-75ce-4dd6-87ca-80104d8e91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Nxs = [150,250] # Considered domain resolutions\n",
    "ppws = [7,8,10,12,15,20] # ppw in flat domain. TODO : take deformation into account.\n",
    "\n",
    "results_Nx = []\n",
    "for Nx in Nxs:\n",
    "    # Build the domain, and coefficients\n",
    "    X,dx = how.make_domain(Nx,2)\n",
    "    ρ,D,make_sol = make_test_a(ρ_flat,D_flat,X,dx,ϕ=ϕ_acoustic)\n",
    "\n",
    "    # Build the hamiltonians\n",
    "    stag2 = ec.staggered(dx,2,'Periodic')\n",
    "    stag4 = ec.staggered(dx,4,'Periodic')\n",
    "    sel_D = Eikonal.VoronoiDecomposition(D)\n",
    "    smooth_D = ts.smooth_decomp(D,order=3)\n",
    "    conv_D = ts.conv_decomp(*ts.deconv(D,σ=2.5,ϵ=1e-2,depth=2)) # order=7 previously\n",
    "#    lin_D = ts.linear_decomp(D) # Non-positive for this anisotropy\n",
    "\n",
    "    # Set a timestep\n",
    "    WaveH = aw.AcousticHamiltonian_Sparse(ρ,sel_D,dx,2)\n",
    "    dt = 0.5*WaveH.dt_max()\n",
    "    T = Nt*dt\n",
    "\n",
    "    WaveHs = [ # All Hamiltonians\n",
    "        (\"CrissCross2\",ec.AcousticCrissCrossH(ρ,D,X,dx,stag2)),\n",
    "        (\"CrissCross4\",ec.AcousticCrissCrossH(ρ,D,X,dx,stag4)),\n",
    "        (\"Centered2\",ec.AcousticCenteredH(ρ,D,X,dx,2)),\n",
    "        (\"Centered4\",ec.AcousticCenteredH(ρ,D,X,dx,4)),\n",
    "#        (\"Centered6\",ec.AcousticCenteredH(ρ,D,X,dx,6)),\n",
    "        (\"Selling2\",WaveH),\n",
    "        (\"Selling4\",aw.AcousticHamiltonian_Sparse(ρ,sel_D,dx,4)),\n",
    "#        (\"Selling6\",aw.AcousticHamiltonian_Sparse(ρ,sel_D,dx,6)),\n",
    "        (\"ConvSelling2\",aw.AcousticHamiltonian_Sparse(ρ,conv_D,dx,2)),\n",
    "        (\"ConvSelling4\",aw.AcousticHamiltonian_Sparse(ρ,conv_D,dx,4)),\n",
    "#        (\"ConvSelling6\",aw.AcousticHamiltonian_Sparse(ρ,conv_D,dx,6)),\n",
    "        (\"SmoothSelling2\",aw.AcousticHamiltonian_Sparse(ρ,smooth_D,dx,2)),\n",
    "        (\"SmoothSelling4\",aw.AcousticHamiltonian_Sparse(ρ,smooth_D,dx,4)),\n",
    "#        (\"SmoothSelling6\",aw.AcousticHamiltonian_Sparse(ρ,smooth_D,dx,6)),\n",
    "         ]\n",
    "     \n",
    "    results_ppw = []\n",
    "    for ppw in ppws:\n",
    "        print(f\"{Nx=}, {ppw=}\")\n",
    "        # Build an exact solution\n",
    "        planewaves = [planewave_with_spatial_frequency(Nx/ppw,planewave) for planewave in planewaves_default_a]\n",
    "        (q_exact,p_exact) = make_sol(planewaves)\n",
    "\n",
    "        # Initial data, and exact final result\n",
    "        q0 = q_exact(  dt/2); p0 = p_exact(0)\n",
    "        qf = q_exact(T+dt/2); pf = p_exact(T)\n",
    "\n",
    "        # Additional parameters\n",
    "        results_scheme = []\n",
    "        for name,WaveH in WaveHs:\n",
    "            q1,p1 = WaveH.Euler_p(q0,p0,dt,niter=Nt)\n",
    "            results_ord = []\n",
    "            for norm_p in (1,2,np.inf):\n",
    "                err = norm(q1-qf,norm_p)/norm(q1,norm_p) # relative error\n",
    "                results_ord.append(err)\n",
    "            results_scheme.append(results_ord)\n",
    "        results_ppw.append(results_scheme)\n",
    "    results_Nx.append(results_ppw)\n",
    "\n",
    "results = np.array(results_Nx) # Nx,ppw,scheme,ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a45dc-8324-4c6b-8cc8-af6422ada6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"CrissCross2\":\"green\",\"CrissCross4\":\"green\",\n",
    "          \"Centered2\":\"blue\",\"Centered4\":\"blue\",\"Centered6\":\"blue\",\n",
    "          \"Selling2\":\"red\",\"Selling4\":\"red\",\"Selling6\":\"red\",\n",
    "          \"ConvSelling2\":\"orange\",\"ConvSelling4\":\"orange\",\"ConvSelling6\":\"orange\",\n",
    "          \"SmoothSelling2\":\"purple\",\"SmoothSelling4\":\"purple\",\"SmoothSelling6\":\"purple\"}\n",
    "schemes6 = colors.keys()\n",
    "schemes4 = [scheme for scheme in colors if scheme[-1] in ('2','4')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125a9a1-00c1-433c-a1df-22ee18392ebb",
   "metadata": {},
   "source": [
    "- The Selling schemes are usually more accurate than the alternatives. Exceptions : \n",
    "  * low resolution, order 6. The Selling schemes are handicapped by their large stencils\n",
    "  * order 6, high ppw, $L^\\infty$ error with non-smooth coefficients, see below.\n",
    "- The Selling variants with smooth coefficients, or with convolved coefficients, are more accurate at high ppw, high order, and in the $L^\\infty$ error.  The difference disappears at low ppw, low order, or in the $L^2$ error. (Note that a little bit of tuning is required to get the correct with $\\sigma$ and relaxation parameter $\\epsilon$ of the deconvolution.)\n",
    "\n",
    "**Note on the sixth order.**\n",
    "The coefficients vary too quickly in the domain to really see the sixth order convergence at the considered domain resolutions.  \n",
    "The Selling schemes are particularly sensitive to this, since they have very quite large stencils due to the combination of high anisotropy and high order. It is unclear wether using sixth order schemes is relevant in applications, given that the coefficients often have discontinuities. In addition, we only use a second order scheme in time, which becomes limiting at high ppw with a sixth order scheme in space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a0989-14e6-4976-b988-c1180d6c98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx=250; err_ord=np.inf\n",
    "schemes = schemes4\n",
    "iNx = Nxs.index(Nx) \n",
    "iord = {1:0,2:1,np.inf:2}[err_ord] \n",
    "for (name,_),error in zip(WaveHs,results[iNx,:,:,iord].T):\n",
    "    if name not in schemes: continue\n",
    "    plt.loglog(ppws,error,label=name,color=colors[name])\n",
    "plt.title(f\"Errors for {Nx=}, norm order={err_ord}\")\n",
    "plt.legend(loc=\"upper right\"); plt.xlabel('ppw'); plt.ylabel('error');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1bf31-e3e3-4c6c-8947-116e089a40c1",
   "metadata": {},
   "source": [
    "More explicitly, the use of smooth coefficients reduces the error by approximately 50% in the most favorable case (fourth order, highest ppw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642b7d3-5a43-4a6f-8170-cdd43e6b18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[name for (name,_) in WaveHs],results[iNx,-1,:,iord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bdb5f-77d7-4f68-a3da-8b0dbe9bb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx=250; err_ord=2\n",
    "schemes = schemes4\n",
    "iNx = Nxs.index(Nx) \n",
    "iord = {1:0,2:1,np.inf:2}[err_ord] \n",
    "for (name,_),error in zip(WaveHs,results[iNx,:,:,iord].T):\n",
    "    if name not in schemes: continue\n",
    "    plt.loglog(ppws,error,label=name,color=colors[name])\n",
    "plt.title(f\"Errors for {Nx=}, norm order={err_ord}\")\n",
    "plt.legend(loc=\"upper right\"); plt.xlabel('ppw'); plt.ylabel('error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c6206-de22-42f5-92dd-c328e2f327d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx=150; err_ord=2\n",
    "schemes = schemes4\n",
    "iNx = Nxs.index(Nx) \n",
    "iord = {1:0,2:1,np.inf:2}[err_ord] \n",
    "for (name,_),error in zip(WaveHs,results[iNx,:,:,iord].T):\n",
    "    if name not in schemes: continue\n",
    "    plt.loglog(ppws,error,label=name,color=colors[name])\n",
    "plt.title(f\"Errors for {Nx=}, norm order={err_ord}\")\n",
    "plt.legend(loc=\"upper right\"); plt.xlabel('ppw'); plt.ylabel('error');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb16cb-90b5-4ff8-802f-4be64114d61a",
   "metadata": {},
   "source": [
    "### 3.5 Elastic accuracy comparison\n",
    "\n",
    "The Selling schemes are more accurate at low ppw and/or low order. \n",
    "For the highest ppw and order (ppw=20, order=4), the Lebedev scheme sometimes becomes more accurate. \n",
    "Possible explanations : \n",
    "- This could be due to the smaller (non-adaptive) stencil of the Lebedev scheme.\n",
    "- This could be the time discretization error (The CFL condition of the lebedev scheme is less strict).\n",
    "\n",
    "For mitigating the second point, we can either reduce the time step, or use a fourth order time integration scheme in time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4609d6b-194f-4822-9e97-52f89d761683",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Problem parameters\n",
    "Nxs = [150] # Considered domain resolutions\n",
    "ppws = [7,8,10,12,15,20] # ppw in flat domain. \n",
    "Nt=100\n",
    "\n",
    "ϵ_elastic = 0.02\n",
    "ϕ_elastic = lambda X:ϕ_default(X,ϵ_elastic)\n",
    "M_flat = np.eye(2)\n",
    "C_flat = Hooke.olivine[0].extract_xz().rotate_by(π/12).hooke; C_flat/=np.max(C_flat)\n",
    "cfl_mult = 0.5\n",
    "\n",
    "results_Nx = []\n",
    "for Nx in Nxs:\n",
    "    # Build the domain, and coefficients\n",
    "    X,dx = how.make_domain(Nx,2)\n",
    "    M,C,S,make_sol = make_test_e(M_flat,C_flat,X,dx,ϕ_elastic)\n",
    "    # Now, the Lebedev scheme. Since point density is doubled, we take this into account. \n",
    "    # In three dimensions, point density would be quadrupled (->replace sqrt(2) with 2**(2/3) in next line)\n",
    "    Nx_Leb = int(np.round(Nx/np.sqrt(2)))\n",
    "    X_Leb,dx_Leb = how.make_domain(Nx_Leb,2)\n",
    "    _,X_10,X_01,_ = ec.shifted_grids(X_Leb,dx_Leb)\n",
    "    M_Leb,C_Leb,S_Leb,_ = make_test_e(M_flat,C_flat,X_Leb,dx_Leb,ϕ=ϕ_elastic)\n",
    "    _,_,_,make_sol_10   = make_test_e(M_flat,C_flat,X_10, dx_Leb,ϕ=ϕ_elastic)\n",
    "    _,_,_,make_sol_01   = make_test_e(M_flat,C_flat,X_01, dx_Leb,ϕ=ϕ_elastic)\n",
    "    \n",
    "\n",
    "    # Build the hamiltonians\n",
    "    stag2 = ec.staggered(dx_Leb,2,'Periodic')\n",
    "    stag4 = ec.staggered(dx_Leb,4,'Periodic')\n",
    "    λ,e = Eikonal.VoronoiDecomposition(C); sel_C = λ,Hooke.moffset(e)\n",
    "    λ,e = ts.conv_decomp(*ts.deconv(C,σ=5,ϵ=5e-4,depth=2)); conv_C = λ,Hooke.moffset(e)\n",
    "    λ,e = Eikonal.VoronoiDecomposition(C,smooth=True); smooth_C = λ,Hooke.moffset(e)\n",
    "#    lin_D = ts.linear_decomp(D) # Non-positive for this anisotropy\n",
    "    # Set a timestep\n",
    "    WaveH = aw.ElasticHamiltonian_Sparse(M,C,dx,2,S) # TODO : sel_C\n",
    "    dt = cfl_mult*WaveH.dt_max()\n",
    "    T = Nt*dt\n",
    "    WaveHs_e = [ # All Hamiltonians\n",
    "        (\"Selling2\",WaveH),\n",
    "        (\"CorrSelling2\",ec.SellingCorrelated2H_ext(M,sel_C, X,dx,2,S)),\n",
    "        (\"ConvSelling2\",ec.SellingCorrelated2H_ext(M,conv_C,X,dx,2,S)),\n",
    "        (\"SmoothSelling2\",ec.SellingCorrelated2H_ext(M,smooth_C,X,dx,2,S)),\n",
    "        (\"Lebedev2\",ec.LebedevH2_ext(M_Leb,C_Leb,stag2,X_Leb,S_Leb)),\n",
    "        (\"Selling4\",aw.ElasticHamiltonian_Sparse(M,C,dx,4,S)), # TODO : sel_C\n",
    "        (\"CorrSelling4\",ec.SellingCorrelated2H_ext(M,sel_C, X,dx,4,S)),\n",
    "        (\"ConvSelling4\",ec.SellingCorrelated2H_ext(M,conv_C,X,dx,4,S)),\n",
    "        (\"SmoothSelling4\",ec.SellingCorrelated2H_ext(M,smooth_C,X,dx,4,S)),\n",
    "        (\"Lebedev4\",ec.LebedevH2_ext(M_Leb,C_Leb,stag4,X_Leb,S_Leb)),\n",
    "#\t\t(\"Sellinv6\",aw.ElasticHamiltonian_Sparse(M,C,dx,6,S)),\n",
    "#\t\t(\"CorrSelling6\",ec.SellingCorrelated2H_ext(M,C,X,dx,6,S)),\t\t\n",
    "        ]\n",
    "    results_ppw = []\n",
    "    for ppw in ppws:\n",
    "        print(f\"{Nx=}, {ppw=}\")\n",
    "        planewaves = [planewave_with_spatial_frequency(Nx/ppw,planewave) for planewave in planewaves_default_e]\n",
    "        # Exact colocated solution\n",
    "        (q_exact,p_exact) = make_sol(planewaves)        \n",
    "        sol_Col = (q_exact(  dt/2),p_exact(0),  \n",
    "                   q_exact(T+dt/2),p_exact(T))\n",
    "        # Exact solution on the Lebedev grids\n",
    "        q_10,p_10 = make_sol_10(planewaves)\n",
    "        q_01,p_01 = make_sol_01(planewaves)\n",
    "        sol_Leb = np.array(((q_10(  dt/2),q_01(  dt/2)), (p_10(0),p_01(0)),\n",
    "                            (q_10(T+dt/2),q_01(T+dt/2)), (p_10(T),p_01(T))))\n",
    "\t\t\n",
    "        # Additional parameters\n",
    "        results_scheme = []\n",
    "        for name,WaveH in WaveHs_e:\n",
    "            q0,p0,qf,pf = sol_Leb if name.startswith(\"Lebedev\") else sol_Col # \n",
    "            q1,p1 = WaveH.Euler_p(q0,p0,dt,niter=Nt)\n",
    "            results_ord = []\n",
    "            for norm_p in (1,2,np.inf):\n",
    "                err = norm(q1-qf,norm_p)/norm(q1,norm_p) # relative error\n",
    "                results_ord.append(err)\n",
    "            results_scheme.append(results_ord)\n",
    "        results_ppw.append(results_scheme)\n",
    "    results_Nx.append(results_ppw)\n",
    "\n",
    "results_e = np.array(results_Nx) # Nx,ppw,scheme,ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802a1cf-1a56-406f-80d1-388a9797738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_e = {\"Lebedev2\":\"blue\",\"Lebedev4\":\"blue\",\n",
    "            \"Selling2\":\"red\",\"Selling4\":\"red\",\"Selling6\":\"red\",\n",
    "            \"CorrSelling2\":\"pink\",\"CorrSelling4\":\"pink\",\"CorrSelling6\":\"pink\",\n",
    "            \"ConvSelling2\":\"orange\",\"ConvSelling4\":\"orange\",\"ConvSelling6\":\"orange\",\n",
    "            \"SmoothSelling2\":\"purple\",\"SmoothSelling4\":\"purple\",\"SmoothSelling6\":\"purple\"}\n",
    "schemes4_e = [scheme for scheme in colors_e if scheme[-1] in ('2','4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e0117-4097-457c-96d2-693f8c1158eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx=150; err_ord=2\n",
    "schemes = schemes4_e\n",
    "iNx = Nxs.index(Nx)\n",
    "iord = {1:0,2:1,np.inf:2}[err_ord] \n",
    "for (name,_),error in zip(WaveHs_e,results_e[iNx,:,:,iord].T):\n",
    "    if name not in schemes: continue\n",
    "    plt.loglog(ppws,error,label=name,color=colors_e[name])\n",
    "plt.title(f\"Errors for {Nx=}, norm order={err_ord}\")\n",
    "plt.legend(loc=\"upper right\"); plt.xlabel('ppw'); plt.ylabel('error');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae62759-eb0b-4ce3-8ea4-a07b77f76b4f",
   "metadata": {},
   "source": [
    "Another example, with a different material, milder domain deformations, and a smaller time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e268e0-863a-4184-ba7e-29647ca13211",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Problem parameters\n",
    "Nxs = [150] # Considered domain resolutions\n",
    "ppws = [7,8,10,12,15,20] # ppw in flat domain. \n",
    "Nt=100\n",
    "\n",
    "ϵ_elastic = 0.01 # Smaller domain deformations\n",
    "ϕ_elastic = lambda X:ϕ_default(X,ϵ_elastic)\n",
    "M_flat = np.eye(2)\n",
    "C_flat = Hooke.stishovite[0].extract_xz().rotate_by(π/8).hooke; C_flat/=np.max(C_flat)\n",
    "cfl_mult = 0.2 # Small time step, otherwise time discretization error dominates\n",
    "\n",
    "results_Nx = []\n",
    "for Nx in Nxs:\n",
    "    # Build the domain, and coefficients\n",
    "    X,dx = how.make_domain(Nx,2)\n",
    "    M,C,S,make_sol = make_test_e(M_flat,C_flat,X,dx,ϕ_elastic)\n",
    "    # Now, the Lebedev scheme. Since point density is doubled, we take this into account. \n",
    "    # In three dimensions, point density would be quadrupled (->replace sqrt(2) with 2**(2/3) in next line)\n",
    "    Nx_Leb = int(np.round(Nx/np.sqrt(2)))\n",
    "    X_Leb,dx_Leb = how.make_domain(Nx_Leb,2)\n",
    "    _,X_10,X_01,_ = ec.shifted_grids(X_Leb,dx_Leb)\n",
    "    M_Leb,C_Leb,S_Leb,_ = make_test_e(M_flat,C_flat,X_Leb,dx_Leb,ϕ=ϕ_elastic)\n",
    "    _,_,_,make_sol_10   = make_test_e(M_flat,C_flat,X_10, dx_Leb,ϕ=ϕ_elastic)\n",
    "    _,_,_,make_sol_01   = make_test_e(M_flat,C_flat,X_01, dx_Leb,ϕ=ϕ_elastic)\n",
    "    \n",
    "\n",
    "    # Build the hamiltonians\n",
    "    stag2 = ec.staggered(dx_Leb,2,'Periodic')\n",
    "    stag4 = ec.staggered(dx_Leb,4,'Periodic')\n",
    "    λ,e = Eikonal.VoronoiDecomposition(C); sel_C = λ,Hooke.moffset(e)\n",
    "    #    smooth_D = Eikonal.VoronoiDecomposition(C,smooth=True)\n",
    "    λ,e = ts.conv_decomp(*ts.deconv(C,σ=5,ϵ=5e-4,depth=2)); conv_C = λ,Hooke.moffset(e)\n",
    "    λ,e = Eikonal.VoronoiDecomposition(C,smooth=True); smooth_C = λ,Hooke.moffset(e)\n",
    "#    lin_D = ts.linear_decomp(D) # Non-positive for this anisotropy\n",
    "    # Set a timestep\n",
    "    WaveH = aw.ElasticHamiltonian_Sparse(M,C,dx,2,S) # TODO : sel_C\n",
    "    dt = cfl_mult*WaveH.dt_max()\n",
    "    T = Nt*dt\n",
    "    WaveHs_e = [ # All Hamiltonians\n",
    "        (\"Selling2\",WaveH),\n",
    "        (\"CorrSelling2\",ec.SellingCorrelated2H_ext(M,sel_C, X,dx,2,S)),\n",
    "        (\"ConvSelling2\",ec.SellingCorrelated2H_ext(M,conv_C,X,dx,2,S)),\n",
    "        (\"SmoothSelling2\",ec.SellingCorrelated2H_ext(M,smooth_C,X,dx,2,S)),\n",
    "        (\"Lebedev2\",ec.LebedevH2_ext(M_Leb,C_Leb,stag2,X_Leb,S_Leb)),\n",
    "        (\"Selling4\",aw.ElasticHamiltonian_Sparse(M,C,dx,4,S)), # TODO : sel_C\n",
    "        (\"CorrSelling4\",ec.SellingCorrelated2H_ext(M,sel_C, X,dx,4,S)),\n",
    "        (\"ConvSelling4\",ec.SellingCorrelated2H_ext(M,conv_C,X,dx,4,S)),\n",
    "        (\"SmoothSelling4\",ec.SellingCorrelated2H_ext(M,smooth_C,X,dx,4,S)),\n",
    "        (\"Lebedev4\",ec.LebedevH2_ext(M_Leb,C_Leb,stag4,X_Leb,S_Leb)),\n",
    "#\t\t(\"Sellinv6\",aw.ElasticHamiltonian_Sparse(M,C,dx,6,S)),\n",
    "#\t\t(\"CorrSelling6\",ec.SellingCorrelated2H_ext(M,C,X,dx,6,S)),\t\t\n",
    "        ]\n",
    "    results_ppw = []\n",
    "    for ppw in ppws:\n",
    "        print(f\"{Nx=}, {ppw=}\")\n",
    "        planewaves = [planewave_with_spatial_frequency(Nx/ppw,planewave) for planewave in planewaves_default_e]\n",
    "        # Exact colocated solution\n",
    "        (q_exact,p_exact) = make_sol(planewaves)        \n",
    "        sol_Col = (q_exact(  dt/2),p_exact(0),  \n",
    "                   q_exact(T+dt/2),p_exact(T))\n",
    "        # Exact solution on the Lebedev grids\n",
    "        q_10,p_10 = make_sol_10(planewaves)\n",
    "        q_01,p_01 = make_sol_01(planewaves)\n",
    "        sol_Leb = np.array(((q_10(  dt/2),q_01(  dt/2)), (p_10(0),p_01(0)),\n",
    "                            (q_10(T+dt/2),q_01(T+dt/2)), (p_10(T),p_01(T))))\n",
    "\t\t\n",
    "        # Additional parameters\n",
    "        results_scheme = []\n",
    "        for name,WaveH in WaveHs_e:\n",
    "            q0,p0,qf,pf = sol_Leb if name.startswith(\"Lebedev\") else sol_Col # \n",
    "            q1,p1 = WaveH.Euler_p(q0,p0,dt,niter=Nt)\n",
    "            results_ord = []\n",
    "            for norm_p in (1,2,np.inf):\n",
    "                err = norm(q1-qf,norm_p)/norm(q1,norm_p) # relative error\n",
    "                results_ord.append(err)\n",
    "            results_scheme.append(results_ord)\n",
    "        results_ppw.append(results_scheme)\n",
    "    results_Nx.append(results_ppw)\n",
    "\n",
    "results_e = np.array(results_Nx) # Nx,ppw,scheme,ord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48a4b7-e487-4b8c-af03-5d814035df6a",
   "metadata": {},
   "source": [
    "This time, the Selling schemes remain consistently ahead. Note that smooth coefficients (convolved, or obtained using the Selling Variant), are needed for optimal convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554103c8-27bd-44b4-9dfc-e3b4be7abf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx=150; err_ord=2\n",
    "schemes = schemes4_e\n",
    "iNx = Nxs.index(Nx)\n",
    "iord = {1:0,2:1,np.inf:2}[err_ord] \n",
    "for (name,_),error in zip(WaveHs_e,results_e[iNx,:,:,iord].T):\n",
    "    if name not in schemes: continue\n",
    "    plt.loglog(ppws,error,label=name,color=colors_e[name])\n",
    "plt.title(f\"Errors for {Nx=}, norm order={err_ord}\")\n",
    "plt.legend(loc=\"upper right\"); plt.xlabel('ppw'); plt.ylabel('error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb9197-867b-4b42-83c4-4c5395120453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
